\chapter{Background} \label{background}


In this chapter, we familiarize the~reader with several topics from machine learning that are used in this thesis. This includes a~brief introduction to neural networks and some more advanced architectures such as convolutional networks or transformers. Finally, we shortly introduce diffusion models, the~model type we use for upscaling images.

\section{Neural networks}

Neural networks are a~type of machine learning model, composed of multiple layers (each of which is parametrized by some weights) and activation functions, each one represented by a~mathematical operation. Each layer either operates on the~output from a~previous layer or on the~model input, making the~whole model a~composite function, producing an~output given input and the~model weights.

The model trains by tweaking the~weights of its layers to minimize a~loss function, which measures how well the~model performs on a~given task. 

We first introduce the~dense layer and ReLU activation function, on which we show the~basics of how a~model learns. After that, we show more advanced layers that will be later used for the~models used in this work. 

\section{Multi-layer perceptron}

The simplest neural network one can build is called a~multi-layer perceptron. It consists of an~input $I \in \mathbf{R}^{n}$, one dense hidden layer, and one dense output layer. A~dense layer has a~matrix of weights $W \in \mathbf{R}^{m \times n}$ and a~vector of biases $b \in \mathbf{R}^n$, where $m$/$n$ are the~input/output dimensions respectively, and a~specified activation function $\sigma$. The~layer output $y$ is then defined as $y = \sigma(x^T \cdot W + b)$, where $\sigma$ is applied to each element of the~output vector individually. A~simple dense neural network is shown in \figref{dense_network}.

\figureimg{dense_network}{A simple MLP network, consisting of three layers - one input layer with 4 units, one dense hidden layer with 6 units and a~\textbf{ReLU} activation, and a~dense output layer with 4 units and a~\textbf{softmax} activation. Each layer is parametrized by weights $W$ and biases $b$. Above each layer, we can see how its output is computed. Each arrow represents one connection - a~single multiplication between a~weight and a~value.}

When illustrating complex neural networks, we do not want to visualize every single element of the~output - we instead just represent individual operations, with arrows indicating which tensors are used as inputs. Consider the~network from \figref{dense_network} - a~more compact representation is shown in \figref{dense_network_compact}. All networks used in this work are presented in this way.


\figureimg{dense_network_compact}{A more compact representation of the~MLP from \figref{dense_network}}


When we provide the~input value $x_{input}$, we can compute the~value of the~first dense layer using its formula, then we repeat the~same for the~second dense layer, producing the~network output.

\section{Training}

To train the~network, we need a~dataset containing examples that can be passed as input to the~first layer and their respective outputs that define what the~model should return for the~given value. We also need to provide a~loss function $L$, which serves as a~measure of how far our model outputs are from the~correct ones, defining what value should our model minimize. Commonly used loss functions include mean squared error for regression tasks and sparse categorical cross-entropy for classification.

Neural networks are trained using gradient descent - we want to compute the~derivative of the~loss function relative to each weight, and then change each weight slightly in the~direction that reduces loss the~most based on the~current training example:

$$w' = w - \alpha \cdot \frac{\partial L}{\partial w}$$

The parameter $\alpha$ is called the~learning rate, and it represents how fast our model should learn.

We begin by passing the~example to the~network input, evaluating the~outputs, and computing the~loss function. After that, we compute the~derivatives of all weights using the~\textbf{back-propagation} algorithm, explained in more detail in the~Deep learning book, further referred to as DLB, \citep{deep_learning_book}, section 6.5.

In practice, there are two major distinctions - the~gradient is averaged over multiple examples, called a~batch, to produce a~more accurate estimate, and the~weights are updated using an~optimizer - an~algorithm that is provided with the~gradient, which it can modify it in some way, and only then updates the~weights. The~optimizers we use in this work are all variations of Adam [described in Section 8.5.3 of DLB \citep{deep_learning_book}], which also tracks the~momentum of the~gradient over multiple batches, and takes this information into account when updating network weights.


\section{Convolutional networks}

\subsection{Convolution basics}

The aforementioned dense layers have several problems for image data - the~image has to be flattened to a~large one-dimensional vector first, completely losing any spatial data, and using another dense layer on top requires an~enormous amount of weight parameters. To alleviate these issues, convolutional layers were introduced in AlexNet \citep{alex_net}.

A convolutional layer can be viewed as an~extension of the~discrete convolution operation between two images. When using one input and one output layer, the~output at a~given position is computed by multiplying the~surrounding pixels in the~input by a~convolutional matrix and applying an~activation to the~result, the~values of which are the~same for every position in the~output and which represent the~trainable weights. We visualize this operation in \figref{convolution}. When using multiple input channels, each layer in the~input has a~separate convolution matrix, and the~convolution results are summed before applying the~activation. When using multiple outputs, each additional layer is computed in the~same way as the~first, just using a~different matrix of weights.


\figureimg{convolution}{Using a~convolutional kernel at coordinates $(1, 1)$. The~same kernel would be used for all other positions as well. Multiple input dimensions would each correspond to a~separate kernel, forming a~kernel stack; multiple output dimensions would use a~different kernel stack each.}


Convolutional layers are great at working with data locally, but unless an~extensive amount of layers is used, they have no way to propagate information to the~other side of the~image. For this reason, downscaling layers were introduced - by using a~greater distance (called stride) between individual matrix placements in the~input, they can downscale the~image, compressing the~information to a~smaller size. When upscaling is required instead, a~transposed convolution can be used - it can be thought of as inserting zeroes after each element in the~input matrix, effectively upscaling it, and then using a~basic convolution.



\subsection{Residual connections and normalization}

Convolutional networks require many layers, each of which performs a~small part of the~whole computation. For large networks, possible issues like \textit{vanishing/exploding gradients}\footnote{During backpropagation, the~gradient is multiplied by the~weights of the~current layer before being propagated back. When there are many layers, and their weights are either too large or too small, the~gradient as a~whole can become significantly smaller or larger during backpropagation, resulting in unstable or slow training.} and increasingly more complex loss landscapes (visualized in \citep{loss_landscape}) become more prominent. To address this, ResNet \citep{resnet} proposes residual connections, which boil down to taking an~input, applying a~series of layers, and then adding the~result to the~original input, forming a~residual block. In the~context of convolutional networks. A~possible configuration is shown in \figref{residual_block}.

\figureimg{residual_block}{A possible residual block configuration. The~bottom, processing part consists of a~2d convolution operation, a~normalization (batch norm is used, but layer norm is common as well), a~ReLU activation, and another convolution. After that, the~result is added to the~input. In cases when we want to change the~number of filters or downscale the~image, we add a~convolutional block on the~residual connection with linear activation.}


Another thing helping with training is new forms of regularization in the~form of normalization layers, which all take some input data and try to shift and scale it so that it has a~unit variance and a~zero mean. The~first to be proposed was a~batch normalization layer \citep{batch_norm}, tracking the~mean and variance of each layer in a~convolutional network, and shifting the~values in each layer to conform to the~properties mentioned above. More advanced forms of normalization appeared later, such as layer normalization \citep{layer_norm} and group normalization \citep{group_norm}, averaging values in each example individually and over groups of layers in an~example respectively.


\section{Transformers}

Transformers were originally introduced in the~field of natural language processing as a~successor to recurrent networks (first mention was in the~BERT article \citep{BERT}). A~transformer layer allows working with sequences of elements, where any element of a~sequence can share information with all other elements at once. A~typical transformer layer consists of two parts, a~multi-head self-attention, which is responsible for interactions between multiple elements, and a~dense layer processing part, which processes each sequence element individually.

The attention is implemented in the~following way - for each element in the~sequence, the~input is a~vector $x \in \mathcal{R}^n$, $n$ is dubbed \texttt{hidden\_size}. The~transformer parameters consist of three matrices, the~key matrix $\mathbf{W^K} \in \mathcal{R}^{n \times d_k}$, value matrix $\mathbf{W^V} \in \mathcal{R}^{n \times d_v}$ and query matrix $\mathbf{W^Q} \in \mathcal{R}^{n \times d_k}$. These are used to compute the~keys $\mathbf{K}=\mathbf{W^K}x$, values $\mathbf{V}=\mathbf{W^V}x$ and queries $\mathbf{Q}=\mathbf{W^Q}x$ - queries representing what we are looking for, keys representing what others should search for if they want to find the~value in this place, and value, representing what will be found at this position. We can then compute the~layer output as follows:

$$Attention(Q, K, V) = softmax \biggl( \frac{QK^T}{\sqrt{d_k}} \biggl) V$$

For reasons mentioned in previous sections, we also have a~residual connection from $x$ to layer output and apply a~layer normalization afterward. We also use multiple attention heads - this means doing the~attention operation multiple times in parallel, with different query, key, and value matrices, concatenating the~result, and using one last dense layer on every sequence element to project the~result to the~required size, before adding the~residual value. The~whole transformer layer is shown in \figref{transformer}.

The processing layer is much simpler - it simply applies a~dense layer with a~different count of units, called \texttt{intermediate\_size}, then an~activation function, and finally another dense layer with \texttt{hidden\_size} units. We then have another residual connection from the~first hidden layer input, add both values together, and apply another layer normalization, obtaining the~transformer layer output.

\figureimg{transformer}{A single transformer layer. The~top block shows how the~multi-head self-attention layer and the~bottom shows the~processing layer. Both of them combined constitute one transformer layer.}



\section{Embeddings}

We often need to represent discrete data and work with them in our neural networks. The~way used in this work is by using embedding layers. These can represent $m$ discrete values in $n$-dimensinal space, by storing an~embedding matrix $E \in \mathbf{R}^{m \times n}$ values. When we need to convert a~discrete value $t \in \mathcal{N}, 0 \leq t < m$ to the~target dimension, we select the~row $E_{t*}$ from the~embedding matrix and return it.

We can also use embeddings to encode information about positions in a~sequence or an~image - by associating each index with a~vector in the~embedding matrix, the~network can learn useful representations for each position. We often add this positional embedding to the~input data before a~transformer layer, so that we can distinguish between different sequence elements inside the~transformer layer.


\section{Diffusion models}

Diffusion models (first mention \citep{diffusion_model_ddpm}, we use a~more advanced version \citep{diffusion_model_ddim}) are a~type of generative neural networks - they learn the~distribution of the~data and can generate new samples. Before describing how generation works, we briefly touch on the~underlying idea, a~Gaussian process.

A Gaussian process consists of multiple steps, where each step adds a~normally distributed noise to the~data (we assume we work with images in this work). The~amount of noise added in each step is described by a~schedule, and over as the~number of steps increases, the~values in the~image with noise added converge to a~normal distribution. Now, if we had a~way to remove noise from images, we could start with a~noisy image nad denoise it multiple times to obtain a~sharp copy, and denoising pure Gaussian noise would lead to a~generated image, leading to a~reverse Gaussian process. Diffusion networks put this idea into practice to generate images, as described below.

Diffusion network can be viewed as a~neural network that approximates the~noise present in the~image, which we can then use to estimate the~noise for each step during the~reverse Gaussian process. Instead of defining the~noise to be added at individual steps, we create a~parameter, $t, t \in [0, 1]$, and a~diffusion schedule $\beta$, denoting the~amount of noise in the~image for each $t$ (and it always holds that $\beta(0) = 1$, $\beta(1)=0$). With this, we can create an~image by estimating the~reverse diffusion process by taking uniform steps over $t$, using the~neural network to estimate the~amount of noise, and subtracting it so that the~noise/image ratio matches in the~next step. Any amount of steps can be performed, with larger numbers leading to results of higher quality.

The most common diffusion network architectures are inspired by U-Net \citep{u_net}, downscaling the~image and upscaling it again. We also provide the~network with the~current noise magnitude, either directly or as a~sinusoidal embedding. To train the~network, we take a~training image, select a~random time from the~decoding schedule $\beta$, mix it with pure Gaussian noise so the~noise-to-signal ratio matches the~schedule value, and minimize the~difference between the~noise prediction based on the~image and the~noise introduced before. It is also possible to learn a~conditional distribution of the~data, for example, how to produce a~sharp image from a~blurred one, this is done by simply providing the~conditional image as input to the~model before predicting the~noise.
